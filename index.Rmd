--- 
title: "Predicción de la venta de vehiculos en Colombia"
author: ""
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
bookdown::pdf_book: default
bookdown::epub_book: default
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: rstudio/bookdown-demo
description: "Asignatura: Series de Tiempo"
---


# ***Presentación***


$Maestría$ $en$ $Ciencia$ $de$ $Datos$

Asignatura: 

 $Series$ $de$ $Tiempo$

Integrantes:

 **$Julieth$ $Cerón$, $Miguel$ $Rodríguez$ $y$ $Emerson$ $Trujillo$**


 
 
# Introducción

El análisis de series de tiempo de venta de vehículos puede proporcionar información valiosa sobre las tendencias y patrones en la demanda de vehículos. Aquí hay algunos pasos generales que se pueden seguir para analizar una serie de tiempo de venta de vehículos:

**• Recopilar datos:** Lo primero que se debe hacer es recopilar datos históricos sobre las ventas de vehículos en un período de tiempo determinado. Estos datos pueden incluir el número de vehículos vendidos por mes, trimestre, año, región geográfica, marca y modelo, entre otros.

**• Visualizar los datos:** Una vez que se han recopilado los datos, es importante visualizarlos en una gráfica de línea o en un diagrama de puntos para identificar patrones y tendencias. La visualización de los datos puede proporcionar una visión general de la serie de tiempo, permitiendo identificar los picos y los valles y los cambios en la tendencia a lo largo del tiempo.

**• Análisis de estacionalidad:** En el análisis de series de tiempo, es común que exista un patrón estacional en los datos, lo que significa que las ventas pueden ser más altas en ciertos meses o épocas del año. Identificar y modelar la estacionalidad puede ayudar a comprender las fluctuaciones en las ventas y mejorar las predicciones futuras.

**• Identificar tendencias y patrones:** Además de la estacionalidad, es importante identificar cualquier tendencia o patrón en los datos. Por ejemplo, puede haber una tendencia general de aumento o disminución de las ventas de vehículos en el tiempo, o puede haber patrones recurrentes a largo plazo que afectan las ventas.

**• Realizar análisis de causalidad:** El análisis de causalidad implica identificar los factores que pueden estar contribuyendo a las tendencias y patrones en los datos. Por ejemplo, pueden existir factores económicos, demográficos o de marketing que estén influyendo en la demanda de vehículos.

**• Modelar y predecir:** Finalmente, se puede utilizar la información obtenida del análisis de series de tiempo para modelar y predecir las ventas futuras de vehículos. Esto puede ayudar a las empresas a planificar su producción y comercialización y ajustar sus estrategias de negocio para maximizar las ventas y minimizar los costos.

La información que se utilizará en el transcurso de la asignatura es de acceso público, ya que es generada por entidades como el DANE, Banco de la República, Fedesarrollo, Fenalco y la ANDI. En la tabla 1 se describen las variables que se incluyen en el dataset de análisis.

## Descripción de las variables del dataset elegido

<img src="C:\Users\portatil\Desktop\Data\EME\Maestría Ciencia de Datos\Semestre 3\Electiva_Series_De_Tiempo\bookdown-demo-main\bookdown\docs\Series-de-Tiempo_files\figure-html\datos_SeriesPrediccion.png"/>

```{r nice-tab, echo=FALSE, message=FALSE, warning=FALSE, tidy=FALSE}
library(readxl)
vehiculos <- read_excel("C:/Users/portatil/DatosR/vehiculos.xlsx")

knitr::kable(
  head(vehiculos, 20),caption = 'Tabla de Datos',
  booktabs = TRUE
)
```

## Justificación 

Para el desarrollo de la asignatura "Análisis de series temporales", se trabajarán con datos mensuales relacionados con consumo, específicamente en bienes durables, con el objetivo de identificar tendencias económicas, cambios en los patrones de gasto y la evolución del poder adquisitivo de los hogares colombianos. Para esto se pronosticará la venta de vehículos nuevos en Colombia, teniendo en cuenta su evolución histórica y posible relación con otras variables que influyen de forma directa e indirecta en su evolución.

Es importante resaltar que hacer un seguimiento activo a la venta de vehículos nuevos en el país cobra relevancia porque es una variable que aproxima el comportamiento del sector automotor y a su vez el consumo de los hogares, dos motores clave de la economía colombiana. El sector automotor, además, impulsa la innovación, la tecnología, la generación de empleo, la movilidad y el desarrollo de otros sectores económicos (a través de encadenamientos productivos).

El pronostico de esta variable permitirá que las empresas y tomadores de decisiones en el ámbito privado o público puedan identificar oportunidades de mercado y tomar decisiones estratégicas, como el lanzamiento de nuevos productos y servicios que satisfagan las necesidades y deseos de los consumidores y, diseñar programas y políticas que fomenten un consumo más sostenible y equitativo.

# Análisis Exploratorio Inicial

Primero, se llevará a cabo un análisis exploratorio de nuestra serie de interés "venta de vehículos (VEH)" para comprender mejor los datos y lograr identificar patrones y características importantes de esta variable. Así, se podran visualizar los datos y detectar patrones de tendencia, estacionalidad, ciclos, y ruido en la serie de tiempo. Esto es fundamental para elegir el modelo adecuado y para tomar decisiones informadas basadas en los datos de la serie.


```{r message=FALSE, warning=FALSE, include=TRUE}
# Instalar y cargar librerias necesarias para el proceso

library(fpp2)
library(readxl)
library(forecast)# Contiene el modelo ARIMA y Holt-Winters
library(tseries) #Para series de tiempo
library(TSA)     #Para series de tiempo
library(urca)    #Para hacer el Test de Raiz Unitaria (detectar hay o no estacionariedad)
library(ggplot2) #Para hacer gráficos
library(dplyr)   #Para la manipulación de datos (filtrar, seleccionar, agregar, transformar)
library(stats)   #Se usa para diversas pruebas estadísticas (medias,varianza, arima,etc)
library(seasonal)#Para calcular la serie ajustada de estacionalidad
library(zoo)     #Para calcular la serie ajustada de estacionalidad
library(prophet) #Para es una biblioteca de Facebook que implementa el algoritmo Prophet para el pronóstico de series de tiempo.
library(tidyverse)
library(lubridate)
library(tidyverse)
library(quantmod)

```

## Serie original

Las variables de análisis es la venta de vehículos nuevos en Colombia. Son datos en frecuencia mensual, disponibles desde enero 2014 hasta febrero 2023.

De acuerdo a la figura 1, se puede apreciar que el comercio de vehículos a nivel nacional en los dos último años se vió fuertemente afectado porla pandemia del Covid-19 y las restricciones de aislamiento y movilidad para contener el avance de la misma, especialmente durante el mes de abril 2020. En el año 2021 y 2022 se evidencia una fase de recuperación.

```{r warning=FALSE}
base <- read_excel("C:/Users/portatil/DatosR/vehiculos_2-3.xlsx")
veh<-ts(base$VEH[1:110], frequency=12, start=c(2014,1))
autoplot(veh,frequency=12,xlab="Años",ylab="No. de vehículos",main="Figura 1. Venta de vehículos en Colombia (original)") 
```

## Promedio móvil

El cálculo del promedio móvil es una técnica común utilizada en el análisis de series de tiempo para suavizar los datos y reducir el ruido. El objetivo es reducir la variabilidad en los datos, lo que puede hacer que las tendencias subyacentes sean más visibles. En esta caso se usará un promedio móvil de orden 3 para no perder tanta información relevante, sobretdo en los últimos dos años de análisis (2021-2022) en donde la economia nacional sufrió un choque sin precendentes.  En la Figura 2. Se observa que el MA(3) suaviza la serie temporal original y elimina la mayoría de las fluctuaciones de corto plazo. Para finales del año 2022, se puede afirmar que la venta de vehículos refleja una tendencia decreciente.

```{r message=FALSE, warning=FALSE, include=TRUE}
library(forecast)
#Calcular promedio móvil de orden 3
promovil<- ma(veh, order = 3)

# Graficar serie original y promedio móvil
ggplot() + 
  geom_line(aes(x = index(veh), y = veh, color = "Serie original")) + 
  geom_line(aes(x = index(promovil), y = promovil, color = "Promedio móvil MA(3)")) + 
  labs(title = "Figura 2. Venta de vehículos con promedio móvil MA(3)",
       x = "Mes-Año",
       y = "Número de vehículos",
       color = "") + 
  theme_minimal()+
  scale_color_manual(values = c("Serie original" = "black", "Promedio móvil MA(3)" = "purple"))

```

## Análisis de rezagos

Para saber cuántas veces debes rezagar una serie de tiempo, es importante analizar la naturaleza de los datos y el objetivo del análisis que se está llevando a cabo. Una forma de determinar la cantidad adecuada de retrasos es mediante la prueba de autocorrelación parcial (PACF), que permite identificar los retardos significativos en una serie de tiempo.

La PACF es una medida de la correlación entre una observación y una observación retrasada, controlando el efecto de las observaciones intermedias. Un retraso significativo en la PACF puede indicar que ese número de retrasos es importante para explicar la serie de tiempo.


```{r message=FALSE, warning=FALSE, include=TRUE}
library(stats)
pacf_veh<- pacf(veh)
plot(pacf_veh)
```

En la gráfica de la PAFC anterior, se observa que un rezago es importante para explicar la serie. Por ende, a continuación aplicamos 1 reago a la serie original de vehículos:

```{r warning=FALSE}
library(stats)
rez_veh <- stats::lag(veh, k = 1)
plot(veh, main = "Serie original y rezagada")
lines(rez_veh, col = "red")
legend("topleft", legend = c("Serie original", "Serie rezagada"), col = c("black", "red"), lty = c(1, 1))
```
 Se concluye que rezagar la serie de tiempo de vehículos ayuda a identificar patrones y relaciones que pueden ser útiles en el análisis y pronóstico de la variable.

## Estacionalidad

Una forma útil de saber si la venta de vehículos tiene estacionalidad, es calcular la función acf que devuelve un gráfico que muestra los coeficientes de correlación para cada rezago. Si la serie de tiempo tiene estacionalidad, se esperaría ver picos en los coeficientes de correlación en los múltiplos de la frecuencia de la serie (por ejemplo, si la frecuencia es mensual, se esperaría ver picos en los coeficientes de correlación para los rezagos 12, 24, 36, etc.). Estos picos indicarían la presencia de patrones de repetición en la serie, lo que sugiere la presencia de estacionalidad.

En este sentido, con la gráfica de ACF de la venta de vehículos que se muestra a continuación se afirma que existe un componente estacional en la venta de vehículos, es decir, por ejemplo que la venta de vehículos en Colombia incrementa en el mes de diciembre de cada año y disminuye en enero. Este comportamiento tiene una relación estrecha con la evolución del consumo, en donde, la temporada decembrina refleja un mayor gasto por parte de los hogares colombianos.


```{r message=FALSE, warning=FALSE, include=TRUE}
acf(veh, lag.max = 48)

```


# Extracción de señales

La extracción de señales en series de tiempo es el proceso de identificar patrones, tendencias y características importantes en los datos de la serie temporal. Es una técnica común utilizada en análisis de series de tiempo para modelar el comportamiento de la serie, predecir valores futuros y entender las relaciones entre las variables.

La extracción de señales incluye el análisis de tendencias, el análisis de ciclos, el análisis de estacionalidad, la identificación de puntos atípicos y la descomposición de series de tiempo.

El objetivo de la extracción de señales es resumir la información en la serie de tiempo de una manera significativa y comprensible, lo que permite a los analistas y tomadores de decisiones identificar patrones y tendencias a largo plazo, así como patrones a corto plazo en los datos. La extracción de señales también puede ser útil para identificar la relación entre las variables de una serie de tiempo y cómo están cambiando a lo largo del tiempo.

En resumen, la extracción de señales en series de tiempo es un proceso crítico para comprender el comportamiento de los datos a lo largo del tiempo y proporciona información valiosa para la toma de decisiones y la predicción de eventos futuros.

##  Descomposición de las series 

Es importante descomponer las series de tiempo porque permite identificar los diferentes componentes que la conforman, es decir, la tendencia, la estacionalidad y la variabilidad aleatoria. Cada uno de estos componentes puede proporcionar información valiosa sobre el comportamiento de la serie a lo largo del tiempo y su relación con otros factores.

*La tendencia* indica que la venta de vehículos refleja un punto de quiebre en marzo 2020 generado por el impacto de la pandemia, luego se evidencia una tendencia positiva de recuperación hasta 2022 y en los primeros dos meses de 2023 se puede observar un ligero cambio de tendencia hacia la desaceleración. 

*La estacionalidad*, por otro lado, refleja patrones repetitivos en la serie a lo largo del tiempo. Se identifica un  patron estacional en diciembre (incremento de la venta de vehículos por influencia estacional) y enero de cada año (detrimento estacional).

Por último, *el componente irregular*, también conocido como ruido, es la parte de la serie que no se puede explicar por la tendencia y la estacionalidad, y puede ser causada por factores impredecibles y/o eventos aleatorios. En este caso,el covid19, un evento sin precedentes e inesperado.


```{r message=FALSE, warning=FALSE, include=TRUE}

# Utilizamos la función decompose (del paquete cargado previamente "STATS")
library(stats)
veh_decomp <- decompose(veh)

# Graficar los componentes
par(mfrow = c(2, 2)) #Se utiliza para dividir la ventana gráfica en una matriz de 2 filas y 2 columnas

plot(veh_decomp$x, main = "Venta de vehículos-Original", col = "black", ylab = "Serie de tiempo")
plot(veh_decomp$trend, main = "Tendencia", col = "blue", ylab = "Valores")
plot(veh_decomp$seasonal, main = "Estacionalidad", col = "red", ylab = "Valores")
plot(veh_decomp$random, main = "Irregularidad", col = "green", ylab = "Valores")
```

# Modelo Holt-Winters
Aquí podemos realizar dos ajustes y graficarlos en comparación con los datos originales para ver la calidad de los ajustes variando los paremetros alpha, beta y gamma.

```{r, message=FALSE}
HW1 <- HoltWinters(veh)
# Custom HoltWinters fitting
HW2 <- HoltWinters(veh, alpha=0.2, beta=0.1, gamma=0.1)
#Visually evaluate the fits
plot(veh, ylab="Ventas de Vehiculos", xlim=c(2014,2023))
lines(HW1$fitted[,1], lty=2, col="blue")
lines(HW2$fitted[,1], lty=2, col="red")
legend("bottomleft", legend = c("Serie original", "HW1","HW2"), col = c("black", "blue", "red"), lty = 1)
```

## Predicciones

Ambos ajustes parecen seguir bastante bien nuestros datos, así que ahora es el momento de ver cómo se desempeñan al predecir las ventas futura de vehiculos Usando la función "predict", necesitaremos especificar cuántos puntos de datos queremos predecir en el futuro. Aquí, usaremos un valor de 24 para proyectar 2 años hacia el futuro (recuerdemos, esta es una serie temporal mensual). También nos gustaría tener una noción de los "intervalos de error" asociados con la predicción para tener una idea de nuestra confianza en la predicción. Para hacer esto, establecemos "prediction.interval=TRUE" y el nivel del intervalo de confianza (seleccionado aquí como 0.95). Una vez más, mostraremos un gráfico que incluya la cola de nuestros datos existentes y las nuevas predicciones.



```{r, message=FALSE}
HW1.pred <- predict(HW1, 24, prediction.interval = TRUE, level=0.95)
#gráfica
plot(veh, ylab="Ventas de Vehiculos", xlim=c(2014,2025))
lines(HW1$fitted[,1], lty=2, col="blue")
lines(HW1.pred[,1], col="red")
lines(HW1.pred[,2], lty=2, col="orange")
lines(HW1.pred[,3], lty=2, col="orange")
legend("bottomleft", legend = c("Serie original", "HW1","pronostico","límites"), col = c("black", "blue", "red","orange"), lty = 1)
```

## Ajuste de la estacionalidad

Cuando realizamos ajustes, también tenemos la opción de ajustar el comportamiento de la componente de estacionalidad. Los ajustes estándar de Holt-Winters utilizan una estacionalidad aditiva, lo que significa que asumen que la amplitud de cualquier componente de estacionalidad es relativamente constante a lo largo de la serie. Sin embargo, si utilizamos una estacionalidad multiplicativa, permitimos que las variaciones estacionales (amplitud) crezcan con el nivel general de los datos. Para ver cómo funciona esto en nuestro caso de ventas de vehículos, crearemos un nuevo ajuste, realizaremos predicciones en el futuro y las compararemos con nuestro ajuste aditivo de HW1.


```{r, message=FALSE}
HW3 <- HoltWinters(veh, seasonal = "multiplicative")
HW3.pred <- predict(HW3, 24, prediction.interval = TRUE, level=0.95)
plot(veh, ylab="Ventas de Vehiculos", xlim=c(2014,2025))
lines(HW3$fitted[,1], lty=2, col="blue")
lines(HW3.pred[,1], col="red")
lines(HW3.pred[,2], lty=2, col="orange")
lines(HW3.pred[,3], lty=2, col="orange")
legend("bottomleft", legend = c("Serie original", "HW-mult","pronostico","límites"), col = c("black", "blue", "red","orange"), lty = 1)
```

Como podemos ver, la predicción se parece bastante a nuestro resultado de HW1, los intervalos de confianza muestran una tendencia más conservadora. Para este conjunto de datos, parece que el ajuste multiplicativo podría ser una mejor opción.

## Uso de Forecast:
Utilizando nuestro ajuste de Holt-Winters HW1 anterior, podemos utilizar "forecast" para hacer nuevas predicciones e incluir intervalos de confianza del 80% y 95%.


```{r, message=FALSE}
library(forecast)
HW1_for <- forecast(HW1, h=24, level=c(80,95))
#grafica
plot(HW1_for, xlim=c(2014, 2026))
lines(HW1_for$fitted, lty=2, col="purple")
```


## Evaluación del modelo

Ahora calculamos la calidad de nuestras predicciones al compilar los valores observados menos los valores predichos para cada punto de datos. Estos se agregan a nuestro modelo de predicción como "\$residuals". Para evaluar mejor las funciones de suavizado que utilizamos en nuestro modelo, queremos verificar que no haya correlaciones entre los errores de predicción. En pocas palabras, si los puntos vecinos en nuestros ajustes constantemente se desvían de los valores observados de manera similar, nuestra línea de ajuste principal no es lo suficientemente reactiva a los cambios en los datos. Para capturar esto, utilizamos la función "acf" para evaluar la correlación de los residuos del ajuste entre puntos con diferentes separaciones temporales en la serie de tiempo (lag). Idealmente, para un lag no nulo, las barras de ACF deben estar dentro del rango de barras azules que se muestran a continuación. Es importante utilizar "na.action=na.pass" porque el último valor de "'\$residuals" siempre es NA y, de lo contrario, la función mostrará un error.

Una prueba de Ljung-Box también puede indicar la presencia de estas correlaciones. Si obtenemos un valor de p > 0.05, hay un 95% de probabilidad de que los residuos sean independientes. Por último, es útil verificar el histograma de los residuos para asegurarnos de que sigan una distribución normal. Si los residuos están muy sesgados, entonces nuestro modelo puede estar constantemente sobrestimando en una dirección.

```{r, message=FALSE}
acf(HW1_for$residuals, lag.max=20, na.action=na.pass)
Box.test(HW1_for$residuals, lag=20, type="Ljung-Box")
hist(HW1_for$residuals)
```

## MAE y RMSE
```{r, message=FALSE}
# Calcular las medidas de precisión
accuracy_hw <- accuracy(HW1_for)

# Obtener el MSE y el MAE
mae_hw <- accuracy_hw[1]
rmse_hw <- accuracy_hw[2]

# Mostrar los resultados
cat("MAE:", mae_hw, "\n")
cat("RMSE:", rmse_hw, "\n")
```


# Aplicación del Modelo Arima

## Validación de Estacionariedad

**Un modelo ARIMA requiere que la serie sea estacionaria**. Se dice que una serie es estacionaria cuando su media, varianza y autocovarianza son invariantes en el tiempo.Esta suposición tiene un sentido intuitivo: dado que ARIMA usa retardos previos de series para modelar su comportamiento.

**RECORDAR:** En el paso anterior se observó graficamente que la serie original de la venta de vehículos tiene una tendencia y ademas no tiene media ni varianza constante.Con lo cual pudieramos afirmar que visualmente la serie pareciera ser NO ESTACIONARIA.

Para validarlo, hacemos el **Test de Dickey Fuller:**. Este test se basa en una regresión lineal que incluye la propia serie de tiempo y sus rezagos.Las hipótesis respectivas son:

**Contraste de hipótesis:**

**H0:** Serie No estacionaria: Hay raiz unitaria   **H1:** Serie Estacionaria: No hay raiz unitaria

Tras realizar la prueba aumentada de Dickey-Fuller (ADF), obtenemos un p-valor = 0.01. Como el p-valor < 0.05,  se rechaza H0. En conclusión, *la venta de vehículos es una variable Estacionaria*. 

```{r message=FALSE, warning=FALSE, include=TRUE}
# Cargar el paquete tseries
library(tseries)
# Realizar prueba de raíz unitaria
adf.test(veh)
```

## Diferenciación 

Dado que la venta de vehículos es una variable estacionaria, no se requiere diferenciar la serie.

## Estimación del modelo Auto.arima


La función auto.arima() es una herramienta muy útil para ajustar modelos ARIMA automáticamente. La idea detrás de esta función es seleccionar automáticamente el mejor modelo ARIMA para una serie de tiempo dada, basándose en criterios estadísticos como el criterio de información de Akaike (AIC) o el criterio de información bayesiano (BIC).

La notación ARIMA(p,d,q)(P,D,Q)[m] se refiere a los parámetros del modelo ARIMA, donde:

p: orden de la parte autoregresiva (AR)
d: orden de diferenciación (I)
q: orden de la parte de media móvil (MA)
P: orden de la parte estacional autoregresiva (SAR)
D: orden de la diferenciación estacional (SI)
Q: orden de la parte estacional de media móvil (SMA)
m: número de períodos en una temporada

*En el modelo ARIMA(1,0,0)(0,1,1)[12]*, el orden AR es 1, el orden MA es 0, el orden de diferenciación es 0, el orden de SAR es 0, el orden de diferenciación estacional es 1, el orden SMA es 1, y el número de períodos en una temporada es 12.

*La interpretación de cada parámetro es la siguiente:*

-*El parámetro AR(1)* indica que se está utilizando la observación más reciente y la observación anterior para predecir la siguiente observación en la serie.

-*El parámetro MA(0)* indica que no se está utilizando ningún término de media móvil para hacer la predicción.

*El parámetro de diferenciación d=0* indica que no se aplicó ninguna diferenciación a la serie.

*El parámetro de diferenciación estacional D=1* indica que se aplicó una diferenciación estacional de primer orden para corregir la estacionalidad en la serie.

*El parámetro SMA(1)* indica que se está utilizando la observación de hace 12 períodos y la observación de hace 1 período para predecir la siguiente observación en la serie.

*En resumen, el modelo ARIMA(1,0,0)(0,1,1)[12] es un modelo que utiliza la observación más reciente y la observación anterior para predecir la siguiente observación en la serie, y también tiene en cuenta la estacionalidad con una diferencia estacional de primer orden y una media móvil estacional de orden 1.*


```{r message=FALSE, warning=FALSE, include=TRUE}
#Corremos la función auto.arima:
autoarimaveh=auto.arima(veh)
autoarimaveh

```

## Validación de supuestos

Analizamos que los residuos sean Ruido Blanco (los residuos se distribuyen normalmente y no hay autocorrelación entre ellos).

Con la prueba de Ljung-Box, se evalúa si hay o no  autocorrelación en los residuos:

**Hipótesis**
**H0:** No hay autocorrelación de los residuos   **H1:** Existe autocorrelación de los residuos

**CONCLUSIÓN: Como el P-value (0.56) es mayor a 0.05 no se rechaza H0. En ese caso si se cumple la condición de los residuos, son ruido blanco (no se correlacionan los errores).**

```{r, message=FALSE}

Box.test(autoarimaveh$residuals, lag = 20, type = "Ljung-Box")
```

## Predicción corto plazo
```{r, message=FALSE}
# Generar pronósticos futuros para 4 años (48 meses)
pronostico <- forecast(autoarimaveh, h = 48)

# Graficar la serie original y el pronóstico
plot(veh, main = "Serie de datos original y pronóstico", xlab = "Fecha", ylab = "Número de vehículos", xlim=c(2014,2026), ylim = c(0, max(veh)))
lines(pronostico$mean, col = "red")
legend("bottomleft", legend = c("Serie original", "Pronóstico"), col = c("black", "red"), lty = 1)
```
## Calculo del AIC Y BIC
```{r, message=FALSE}
# Calcular el AIC y el BIC
aic <- AIC(autoarimaveh)
bic <- BIC(autoarimaveh)

# Mostrar los resultados
cat("AIC:", aic, "\n")
cat("BIC:", bic, "\n")
```
## Evaluación del Modelo - MAE y RMSE
```{r, message=FALSE}
# Calcular las medidas de precisión
accuracy_arima <- accuracy(autoarimaveh)

# Obtener el MSE y el MAE
mae_arima <- accuracy_arima[1]
rmse_arima <- accuracy_arima[2]

# Mostrar los resultados
cat("MAE:", mae_arima, "\n")
cat("RMSE:", rmse_arima, "\n")
```

## Comparación de los modelos ARIMA y Holt-Winters:

Comparando los resultados de los modelos ARIMA y Holt-Winters en términos de las métricas de precisión, podemos hacer las siguientes conclusiones:

**MAE (Mean Absolute Error):**

El modelo ARIMA tiene un MAE de -155.7058, mientras que el modelo Holt-Winters tiene un MAE de 259.0023.
En términos del MAE, el modelo ARIMA muestra un menor error absoluto promedio en comparación con el modelo Holt-Winters.
Un valor de MAE más bajo indica que el modelo ARIMA tiene una mejor precisión en los pronósticos en comparación con el modelo Holt-Winters.

**RMSE (Root Mean Squared Error):**

El modelo ARIMA tiene un RMSE de 2912.711, mientras que el modelo Holt-Winters tiene un RMSE de 3263.144.
En términos del RMSE, el modelo ARIMA muestra un valor más bajo, lo que indica un menor error cuadrático promedio en comparación con el modelo Holt-Winters.
Un valor de RMSE más bajo también indica que el modelo ARIMA tiene un mejor ajuste y mayor precisión en los pronósticos en comparación con el modelo Holt-Winters.

# Modelo Facebook Prophet

El modelo Facebook Prophet es una herramienta útil para el análisis y pronóstico de series de tiempo debido a su facilidad de uso, flexibilidad en la configuración del modelo, capacidad de manejo de tendencias y estacionalidades, robustez ante datos faltantes y anomalías, y la disponibilidad de herramientas de visualización y diagnóstico. Esto lo convierte en una opción popular para aplicaciones prácticas en una amplia gama de sectores, incluyendo finanzas, comercio electrónico, planificación de la demanda, entre otros.
Para nuestro caso de ventas de vehiculos en Colombia inicimos ajuste del modelo para evaluar rendimeinto:

Creamos la serie de tiempo
```{r message=FALSE, warning=FALSE}
veh <- ts(base$VEH[1:110], frequency = 12, start = c(2014, 1))
```

Ajustamos el modelo ARIMA
```{r message=FALSE, warning=FALSE}
arima_model <- forecast::auto.arima(veh)

```

Ajustamos el modelo Prophet
```{r message=FALSE, warning=FALSE}
veh_data <- data.frame(ds = seq(as.Date("2014-01-01"), by = "month", length.out = 110), y = base$VEH[1:110])
prophet_model <- prophet(veh_data)
```

Generamos pronósticos

```{r message=FALSE, warning=FALSE}

horizon <- 12  # Número de períodos para pronosticar

# Pronóstico ARIMA
arima_forecast <- forecast(arima_model, h = horizon)

# Pronóstico Prophet
future_data <- make_future_dataframe(prophet_model, periods = horizon, freq = "month")
prophet_forecast <- predict(prophet_model, future_data)

# Convertir los pronósticos de Prophet a una serie de tiempo
prophet_forecast_ts <- ts(prophet_forecast$yhat, frequency = horizon, start = c(2014, 1))

# Graficar los pronósticos y los datos originales
plot(veh, xlab = "Años", ylab = "No. de vehículos", main = "Venta de vehículos en Colombia (original)")
lines(arima_forecast$mean, col = "blue", lty = 1)
lines(prophet_forecast_ts, col = "red", lty = 1)
legend("topleft", legend = c("Datos originales", "ARIMA", "Prophet"), col = c("black", "blue", "red"), lty = c(1, 1, 1))

```

## Analisis de predicción de los Modelos

Al comparar los datos que predice cada modelo en el futuro, es evidente que el modelo Prophet presenta una mejor capacidad para capturar las fluctuaciones y patrones en la serie de tiempo de ventas de vehículos en Colombia. Los pronósticos generados por Prophet se ajustan más de cerca a los datos reales y reflejan de manera más precisa las tendencias observadas en la serie.

En contraste, los pronósticos del modelo ARIMA muestran ciertas desviaciones y no logran capturar completamente las variaciones en la serie de tiempo. Esto se puede observar al comparar las líneas de pronóstico en los períodos futuros. Mientras que los pronósticos de Prophet siguen de cerca las fluctuaciones y cambios en la serie, los pronósticos de ARIMA pueden estar más alejados de los valores reales y no reflejar con precisión las tendencias observadas.

Esto se confirma al evaluar las métricas de desempeño (MAE y RMSE), donde el modelo Prophet muestra valores más bajos en comparación con el modelo ARIMA. Un MAE y RMSE más bajo indica una mayor precisión en los pronósticos, lo que respalda aún más la superioridad de Prophet en términos de predicción de la serie de tiempo.



##  Evaluación del Modelo - MAE y RMSE


Calculamos MAE y RMSE para ARIMA

```{r message=FALSE, warning=FALSE}
arima_forecast_values <- as.numeric(arima_forecast$mean)
mae_arima <- mean(abs(arima_forecast_values - veh))
rmse_arima <- sqrt(mean((arima_forecast_values - veh)^2))
```

Calculamos MAE y RMSE para Prophet

```{r message=FALSE, warning=FALSE}
mae_prophet <- mean(abs(prophet_forecast_ts - veh))
rmse_prophet <- sqrt(mean((prophet_forecast_ts - veh)^2))
```

Imprimimos resultados
```{r message=FALSE, warning=FALSE}

cat("ARIMA - MAE:", mae_arima, "\n")
cat("ARIMA - RMSE:", rmse_arima, "\n")
cat("Prophet - MAE:", mae_prophet, "\n")
cat("Prophet - RMSE:", rmse_prophet, "\n")

```

## Comparación de los modelos ARIMA y Prophet:

Comparando los valores de MAE y RMSE, podemos observar que el modelo Prophet tiene un mejor desempeño en términos de precisión en los pronósticos en comparación con el modelo ARIMA. Esto se evidencia en los valores más bajos tanto en el MAE como en el RMSE para el modelo Prophet.

El MAE para el modelo Prophet es de 2330.432, lo que indica una menor diferencia absoluta promedio entre los valores pronosticados y los valores reales. Por otro lado, el MAE para el modelo ARIMA es de 4910.315, lo que implica una mayor diferencia promedio entre los pronósticos y los valores reales.

En cuanto al RMSE, el modelo Prophet también muestra un mejor desempeño con un valor de 3220.954, en comparación con el modelo ARIMA que tiene un RMSE de 6504.895. Esto indica que el modelo Prophet tiene una menor magnitud de error cuadrático medio en comparación con el modelo ARIMA.

Estos resultados sugieren que el modelo Prophet es más preciso en la predicción de la serie de tiempo de ventas de vehículos en Colombia, en comparación con el modelo ARIMA utilizado en este análisis.

En conclusión, en base a los resultados obtenidos, el modelo Prophet muestra un mejor desempeño en términos de precisión en los pronósticos para la serie de tiempo de ventas de vehículos en Colombia, con valores más bajos tanto en el MAE como en el RMSE.


# Redes Neuronales Recurrentes (Modelos Elman y Jordan)


Una red neuronal recurrente no tiene una estructura de capas definida, sino que permiten conexiones arbitrarias entre las neuronas, incluso pudiendo crear ciclos, con esto se consigue crear la temporalidad, permitiendo que la red tenga memoria.

Los RNN se denominan recurrentes porque realizan la misma tarea para cada elemento de una secuencia, y la salida depende de los cálculos anteriores.

**MODELO ELMAN**

En las redes de Elman, las entradas de estas neuronas, se toman desde las salidas de las neuronas de una de las capas ocultas, y sus salidas se conectan de nuevo en las entradas de esta misma capa, lo que proporciona una especie de memoria sobre el estado anterior de dicha capa.

Creamos la serie de tiempo

```{r message=FALSE, warning=FALSE}
veh <- read_excel("C:/Users/portatil/DatosR/veh.xlsx")
Y=ts(veh, start = c(2014,1),frequency = 12)

```

Damos formato de serie de tiempo
```{r}
Y1=ts(veh, start = c(2014,1), end=c(2022,02),frequency = 12)
length(Y1)
```

Para aplicar redes neuronales debemos normalizar datos
Para ello hemos asociado a nuestro dataset de base una variable “Z” y a partir de esta hemos realizar la normalización a través de la variable “S”.

```{r message=FALSE, warning=FALSE}
Z <- as.ts(Y1,F)
S <- (Z-min(Z))/(max(Z)-min(Z))  
plot(S)

```

A continuación comprobamos el numero de filas totales que contiene nuestro dataset.
```{r message=FALSE, warning=FALSE}
tamano_total <- length(S)
tamano_total
```

Ahora dividiremos los conjuntos de entrenamiento en un 75% y prueba en un 25% respectivamente.
```{r message=FALSE, warning=FALSE}
tamano_train <- round(tamano_total*0.75, digits = 0)
train <- 0:(tamano_train-1)
train
```
```{r}
test <- (tamano_train):tamano_total
test
```

Ahora crearemos un dataframe con n columnas, cada una de las cuales adelantara 
un valor de la serie en el futuro, a través de una variable tipo zoo, equivalente al #periodo de retardo de la serie.
```{r message=FALSE, warning=FALSE}

y <- as.zoo(S)
x1 <- Lag(y, k = 1)
x2 <- Lag(y, k = 2)
x3 <- Lag(y, k = 3)
x4 <- Lag(y, k = 4)
x5 <- Lag(y, k = 5)
x6 <- Lag(y, k = 6)
x7 <- Lag(y, k = 7)
x8 <- Lag(y, k = 8)
x9 <- Lag(y, k = 9)
x10 <- Lag(y, k = 10)
x11 <- Lag(y, k = 11)
x12 <- Lag(y, k = 12)
slogN <- cbind(y,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12)
```
```{r message=FALSE, warning=FALSE}
DT::datatable(slogN)
```
A continuación eliminaremos los valores NA producidos al desplazar la serie:
```{r message=FALSE, warning=FALSE}
slogN1 <- slogN[-(1:12),]
DT::datatable(slogN1)
```

Luego definimos los valores de entrada y salida de la red neuronal:
```{r}

inputs <- slogN1[,2:13]
outputs <- slogN1[,1]
```


Ahora crearemos la red de Elman, probando diferentes tipos de combinaciones de neuronas en las capas ocultas e iteraciones máximas, ademas del ritmo de aprendizaje, para ajustar lo mejor posible la curva de predicción a la del modelo de la serie. De esta forma hemos llegado a estos valores a la hora de crear nuestra red. Asi mismo ponemos una semilla para que el resultado sea reproducible.

```{r message=FALSE, warning=FALSE}
library(RSNNS)
set.seed(42)
fit<-elman(inputs[train],outputs[train],size=5,learnFuncParams=c(0.1),
                  maxit=10000)
```

```{r message=FALSE, warning=FALSE}
#En la gráfica siguiente vemos como evoluciona el error de la red con el numero de iteraciones para los parámetros expuestos.

plotIterativeError(fit, main = "Iterative Error for 5 Neuron")
```
En la gráfica anterior se observa una convergencia rápida hacia cero, se espera entonces un ajuste rápido del modelo.

Ahora realizamos la predicción con el resto de los términos de la serie que son los datos #seleccionados para test, pasamos pues una vez entrenada a probarla y a representarla #graficamente para ver el ajuste del modelo.

```{r message=FALSE, warning=FALSE}
y <- as.vector(outputs[-test])
plot(y,type="l")
pred <- predict(fit, inputs[-test])
lines(pred,col = "red")
legend("topleft", legend = c("Datos Reales", "Datos Predichos"), 
       col = c("black", "red"), lty = c(1, 1))

```
**El ajuste  predice bastante bien con los parametros elegidos, pues la curva del modelo de la serie y la de la prediccion parecen bastante ajustadas.**

Esta representacion grafica se puede utilizar para ir ajustando la prediccion y el modelo a medida que vamos probando diferentes parametros de la red de Elman, de forma que la curva del modelo y de la prediccion queden lo mas ajustados posibles.

Ahora gracias al efecto memoria vamos a adelantarle a la serie al menos en un valor con una precision muy buena. Para ello volveremos a introducir los datos de entrenamiento.

```{r message=FALSE, warning=FALSE}

predictions <- predict(fit,inputs[-train])
predictions

```

Posteriori desnormalizaremos los datos:
```{r message=FALSE, warning=FALSE}
mod1 <- predictions*(max(Z)-min(Z))+min(Z)
mod1
```

Aquí vemos la gráfica con los valores pronosticados con la linea roja.
-Los valores que adelantamos en el tiempo corresponden a mod1, de los cuales adelantaremos 12 meses a futuro para nuestro estudio.

Ahora veamos la representación de los valores predecidos para el siguiente periodo.
```{r message=FALSE, warning=FALSE}
x <- 1:(tamano_total+length(mod1))
y <- c(as.vector(Z),mod1)
plot(x[1:tamano_total], y[1:tamano_total],col = "blue", type="l")
lines( x[(tamano_total):length(x)], y[(tamano_total):length(x)], col="red")

length(y)
```


**MODELO JORDAN**

En las redes Jordan, la diferencia esta en que la entrada de las neuronas de la capa de contexto se toma desde la salida de la red.

Realizamos las mismas operaciones que con la red Elman, sustituyendo el modelo, obtenemos el resultado para la red Jordan.

```{r message=FALSE, warning=FALSE}
set.seed(42)
fit <-jordan(inputs[train],outputs[train],size=5,learnFuncParams=c(0.1),
             maxit=35000)

plotIterativeError(fit, main = "Iterative Error for 5 Neuron")
```

```{r message=FALSE, warning=FALSE}
y <- as.vector(outputs[-test])
plot(y, type = "l", main = "Comparación de Datos Reales y Predichos", 
     xlab = "Índice", ylab = "Valores")
pred <- predict(fit, inputs[-test])
lines(pred, col = "red")
legend("topleft", legend = c("Datos Reales", "Datos Predichos"), 
       col = c("black", "red"), lty = c(1, 1))
```

```{r message=FALSE, warning=FALSE}
predictions <- predict(fit,inputs[-train])
mod2 <- predictions*(max(Z)-min(Z))+min(Z)
mod2
```

```{r message=FALSE, warning=FALSE}
x <- 1:(tamano_total+length(mod2))
y <- c(as.vector(Z),mod2)
plot(x[1:tamano_total], y[1:tamano_total],col = "blue", type="l")
lines( x[(tamano_total):length(x)], y[(tamano_total):length(x)], col="red")
```

## Estimación del error Comparativo de los modelos con los valores actuales observados.

```{r message=FALSE, warning=FALSE}
data=veh[99:110,]
data_real <- ts(data, start = c(2022,3), end=c(2023,02), frequency = 12)

data_real
```

Para Elman y Jordan al no ser modelos con forecast, lo convertimos en series de tiempo #para que lo acepte el comando accuracy.De tal forma que:

```{r message=FALSE, warning=FALSE}
mod1[1:12]

```
```{r message=FALSE, warning=FALSE}
m1 <- mod1[1:12]
mod1c <- ts(m1, frequency=12,start=c(2022,3))
mod1c
```
```{r message=FALSE, warning=FALSE}
m2 <- mod2[1:12]
mod2c <- ts(m2, frequency=12,start=c(2022,3))
mod2c
```
**ELMAN (RRN)**

```{r message=FALSE, warning=FALSE}
accuracy(mod1c,data_real)
```
**JORDAN**

```{r message=FALSE, warning=FALSE}
accuracy(mod2c,data_real)
```

## Conclusiones de modelos de redes neuronales ELMAN y JORDAN.


**Para el modelo ELMAN (RRN):**

El error medio (ME) es de 3918.892, indicando una ligera tendencia a subestimar los valores reales en promedio.

El error cuadrático medio (RMSE) es de 8467.508, lo que sugiere una variabilidad considerable entre los valores predichos y los valores reales.

El error absoluto medio (MAE) es de 6560.378, que representa la diferencia promedio entre los valores predichos y los valores reales.

El error porcentual medio (MPE) es de 14.71541, lo que indica una tendencia a subestimar los valores reales en promedio.

El error absoluto porcentual medio (MAPE) es de 32.55703, que representa la diferencia promedio entre los valores predichos y los valores reales en términos porcentuales.

El coeficiente de autocorrelación (ACF1) es de 0.5280143, lo que sugiere cierta correlación entre los valores predichos y los valores reales.

El índice de Theil (Theil's U) es de 3.23668, proporcionando una medida de la relación entre el error de predicción y la variabilidad de los datos reales.

**Para el modelo JORDAN:**

El error medio (ME) es de 2591.269, indicando una ligera tendencia a subestimar los valores reales en promedio.

El error cuadrático medio (RMSE) es de 8999.551, lo que sugiere una mayor variabilidad entre los valores predichos y los valores reales en comparación con el modelo ELMAN.

El error absoluto medio (MAE) es de 7732.16, que representa la diferencia promedio entre los valores predichos y los valores reales.

El error porcentual medio (MPE) es de 8.647962, lo que indica una tendencia a subestimar los valores reales en promedio.

El error absoluto porcentual medio (MAPE) es de 38.0191, que representa una mayor diferencia promedio entre los valores predichos y los valores reales en términos porcentuales en comparación con el modelo ELMAN.

El coeficiente de autocorrelación (ACF1) es de -0.1205701, lo que sugiere una correlación débil o falta de correlación entre los valores predichos y los valores reales.

El índice de Theil (Theil's U) es de 2.92748, proporcionando una medida de la relación entre el error de predicción y la variabilidad de los datos reales.

**En conclusión**, según los resultados presentados, el modelo ELMAN (RRN) muestra un error ligeramente menor en términos de RMSE y MAE en comparación con el modelo JORDAN. También exhibe una correlación más fuerte entre los valores predichos y los valores reales, como se indica por el coeficiente de autocorrelación (ACF1). 


