[["index.html", "Predicción de la venta de vehiculos en Colombia Chapter 1 Presentación", " Predicción de la venta de vehiculos en Colombia 2023-06-18 Chapter 1 Presentación \\(Maestría\\) \\(en\\) \\(Ciencia\\) \\(de\\) \\(Datos\\) Asignatura: \\(Series\\) \\(de\\) \\(Tiempo\\) Integrantes: \\(Julieth\\) \\(Cerón\\), \\(Miguel\\) \\(Rodríguez\\) \\(y\\) \\(Emerson\\) \\(Trujillo\\) "],["introducción.html", "Chapter 2 Introducción 2.1 Descripción de las variables del dataset elegido 2.2 Justificación", " Chapter 2 Introducción El análisis de series de tiempo de venta de vehículos puede proporcionar información valiosa sobre las tendencias y patrones en la demanda de vehículos. Aquí hay algunos pasos generales que se pueden seguir para analizar una serie de tiempo de venta de vehículos: • Recopilar datos: Lo primero que se debe hacer es recopilar datos históricos sobre las ventas de vehículos en un período de tiempo determinado. Estos datos pueden incluir el número de vehículos vendidos por mes, trimestre, año, región geográfica, marca y modelo, entre otros. • Visualizar los datos: Una vez que se han recopilado los datos, es importante visualizarlos en una gráfica de línea o en un diagrama de puntos para identificar patrones y tendencias. La visualización de los datos puede proporcionar una visión general de la serie de tiempo, permitiendo identificar los picos y los valles y los cambios en la tendencia a lo largo del tiempo. • Análisis de estacionalidad: En el análisis de series de tiempo, es común que exista un patrón estacional en los datos, lo que significa que las ventas pueden ser más altas en ciertos meses o épocas del año. Identificar y modelar la estacionalidad puede ayudar a comprender las fluctuaciones en las ventas y mejorar las predicciones futuras. • Identificar tendencias y patrones: Además de la estacionalidad, es importante identificar cualquier tendencia o patrón en los datos. Por ejemplo, puede haber una tendencia general de aumento o disminución de las ventas de vehículos en el tiempo, o puede haber patrones recurrentes a largo plazo que afectan las ventas. • Realizar análisis de causalidad: El análisis de causalidad implica identificar los factores que pueden estar contribuyendo a las tendencias y patrones en los datos. Por ejemplo, pueden existir factores económicos, demográficos o de marketing que estén influyendo en la demanda de vehículos. • Modelar y predecir: Finalmente, se puede utilizar la información obtenida del análisis de series de tiempo para modelar y predecir las ventas futuras de vehículos. Esto puede ayudar a las empresas a planificar su producción y comercialización y ajustar sus estrategias de negocio para maximizar las ventas y minimizar los costos. La información que se utilizará en el transcurso de la asignatura es de acceso público, ya que es generada por entidades como el DANE, Banco de la República, Fedesarrollo, Fenalco y la ANDI. En la tabla 1 se describen las variables que se incluyen en el dataset de análisis. 2.1 Descripción de las variables del dataset elegido Table 2.1: Tabla de Datos …1 VEH INF ISE ISE_COM ICC IEC ICE TRM 2014-01-01 20115 2.13 89.38968 86.54366 27.3 28.2 25.9 1960.41 2014-02-01 23744 2.32 92.91968 90.38523 15.7 14.8 17.2 2040.51 2014-03-01 24075 2.51 95.65122 91.39628 18.5 18.0 19.3 2022.19 2014-04-01 26128 2.72 92.32801 95.26309 18.5 16.2 21.8 1939.27 2014-05-01 26865 2.93 95.56390 93.78647 23.9 22.7 25.8 1915.46 2014-06-01 22974 2.79 95.43544 94.05604 26.5 28.6 23.4 1888.10 2014-07-01 27650 2.89 97.57987 100.33581 26.6 25.9 27.6 1858.40 2014-08-01 27465 3.02 97.52460 95.69554 20.5 16.0 27.2 1899.07 2014-09-01 29528 2.86 98.39200 94.23638 17.5 16.2 19.4 1971.34 2014-10-01 31386 3.29 98.34370 97.17163 21.7 20.9 22.8 2047.03 2014-11-01 25700 3.65 101.97067 102.50636 24.5 24.2 24.9 2127.25 2014-12-01 40393 3.66 109.07255 119.93755 22.4 21.8 23.3 2344.23 2015-01-01 21241 3.82 92.03554 90.26399 17.9 18.1 17.7 2397.69 2015-02-01 22871 4.36 95.19647 92.84614 14.0 14.0 13.9 2420.38 2015-03-01 24671 4.56 98.60194 94.88460 2.3 0.3 5.2 2586.58 2015-04-01 21863 4.64 95.51865 96.84447 8.2 8.0 8.5 2495.36 2015-05-01 22525 4.41 98.91425 96.47525 13.7 13.8 13.5 2439.09 2015-06-01 22476 4.42 99.30745 97.80433 14.7 11.2 20.1 2554.94 2015-07-01 26595 4.46 102.02717 103.78699 2.6 2.2 3.3 2731.90 2015-08-01 23208 4.74 101.20712 99.29043 -0.4 4.7 -8.0 3023.29 2.2 Justificación Para el desarrollo de la asignatura “Análisis de series temporales”, se trabajarán con datos mensuales relacionados con consumo, específicamente en bienes durables, con el objetivo de identificar tendencias económicas, cambios en los patrones de gasto y la evolución del poder adquisitivo de los hogares colombianos. Para esto se pronosticará la venta de vehículos nuevos en Colombia, teniendo en cuenta su evolución histórica y posible relación con otras variables que influyen de forma directa e indirecta en su evolución. Es importante resaltar que hacer un seguimiento activo a la venta de vehículos nuevos en el país cobra relevancia porque es una variable que aproxima el comportamiento del sector automotor y a su vez el consumo de los hogares, dos motores clave de la economía colombiana. El sector automotor, además, impulsa la innovación, la tecnología, la generación de empleo, la movilidad y el desarrollo de otros sectores económicos (a través de encadenamientos productivos). El pronostico de esta variable permitirá que las empresas y tomadores de decisiones en el ámbito privado o público puedan identificar oportunidades de mercado y tomar decisiones estratégicas, como el lanzamiento de nuevos productos y servicios que satisfagan las necesidades y deseos de los consumidores y, diseñar programas y políticas que fomenten un consumo más sostenible y equitativo. "],["análisis-exploratorio-inicial.html", "Chapter 3 Análisis Exploratorio Inicial 3.1 Serie original 3.2 Promedio móvil 3.3 Análisis de rezagos 3.4 Estacionalidad", " Chapter 3 Análisis Exploratorio Inicial Primero, se llevará a cabo un análisis exploratorio de nuestra serie de interés “venta de vehículos (VEH)” para comprender mejor los datos y lograr identificar patrones y características importantes de esta variable. Así, se podran visualizar los datos y detectar patrones de tendencia, estacionalidad, ciclos, y ruido en la serie de tiempo. Esto es fundamental para elegir el modelo adecuado y para tomar decisiones informadas basadas en los datos de la serie. # Instalar y cargar librerias necesarias para el proceso library(fpp2) library(readxl) library(forecast)# Contiene el modelo ARIMA y Holt-Winters library(tseries) #Para series de tiempo library(TSA) #Para series de tiempo library(urca) #Para hacer el Test de Raiz Unitaria (detectar hay o no estacionariedad) library(ggplot2) #Para hacer gráficos library(dplyr) #Para la manipulación de datos (filtrar, seleccionar, agregar, transformar) library(stats) #Se usa para diversas pruebas estadísticas (medias,varianza, arima,etc) library(seasonal)#Para calcular la serie ajustada de estacionalidad library(zoo) #Para calcular la serie ajustada de estacionalidad library(prophet) #Para es una biblioteca de Facebook que implementa el algoritmo Prophet para el pronóstico de series de tiempo. library(tidyverse) library(lubridate) library(tidyverse) library(quantmod) 3.1 Serie original Las variables de análisis es la venta de vehículos nuevos en Colombia. Son datos en frecuencia mensual, disponibles desde enero 2014 hasta febrero 2023. De acuerdo a la figura 1, se puede apreciar que el comercio de vehículos a nivel nacional en los dos último años se vió fuertemente afectado porla pandemia del Covid-19 y las restricciones de aislamiento y movilidad para contener el avance de la misma, especialmente durante el mes de abril 2020. En el año 2021 y 2022 se evidencia una fase de recuperación. base &lt;- read_excel(&quot;C:/Users/portatil/DatosR/vehiculos_2-3.xlsx&quot;) veh&lt;-ts(base$VEH[1:110], frequency=12, start=c(2014,1)) autoplot(veh,frequency=12,xlab=&quot;Años&quot;,ylab=&quot;No. de vehículos&quot;,main=&quot;Figura 1. Venta de vehículos en Colombia (original)&quot;) 3.2 Promedio móvil El cálculo del promedio móvil es una técnica común utilizada en el análisis de series de tiempo para suavizar los datos y reducir el ruido. El objetivo es reducir la variabilidad en los datos, lo que puede hacer que las tendencias subyacentes sean más visibles. En esta caso se usará un promedio móvil de orden 3 para no perder tanta información relevante, sobretdo en los últimos dos años de análisis (2021-2022) en donde la economia nacional sufrió un choque sin precendentes. En la Figura 2. Se observa que el MA(3) suaviza la serie temporal original y elimina la mayoría de las fluctuaciones de corto plazo. Para finales del año 2022, se puede afirmar que la venta de vehículos refleja una tendencia decreciente. library(forecast) #Calcular promedio móvil de orden 3 promovil&lt;- ma(veh, order = 3) # Graficar serie original y promedio móvil ggplot() + geom_line(aes(x = index(veh), y = veh, color = &quot;Serie original&quot;)) + geom_line(aes(x = index(promovil), y = promovil, color = &quot;Promedio móvil MA(3)&quot;)) + labs(title = &quot;Figura 2. Venta de vehículos con promedio móvil MA(3)&quot;, x = &quot;Mes-Año&quot;, y = &quot;Número de vehículos&quot;, color = &quot;&quot;) + theme_minimal()+ scale_color_manual(values = c(&quot;Serie original&quot; = &quot;black&quot;, &quot;Promedio móvil MA(3)&quot; = &quot;purple&quot;)) 3.3 Análisis de rezagos Para saber cuántas veces debes rezagar una serie de tiempo, es importante analizar la naturaleza de los datos y el objetivo del análisis que se está llevando a cabo. Una forma de determinar la cantidad adecuada de retrasos es mediante la prueba de autocorrelación parcial (PACF), que permite identificar los retardos significativos en una serie de tiempo. La PACF es una medida de la correlación entre una observación y una observación retrasada, controlando el efecto de las observaciones intermedias. Un retraso significativo en la PACF puede indicar que ese número de retrasos es importante para explicar la serie de tiempo. library(stats) pacf_veh&lt;- pacf(veh) plot(pacf_veh) En la gráfica de la PAFC anterior, se observa que un rezago es importante para explicar la serie. Por ende, a continuación aplicamos 1 reago a la serie original de vehículos: library(stats) rez_veh &lt;- stats::lag(veh, k = 1) plot(veh, main = &quot;Serie original y rezagada&quot;) lines(rez_veh, col = &quot;red&quot;) legend(&quot;topleft&quot;, legend = c(&quot;Serie original&quot;, &quot;Serie rezagada&quot;), col = c(&quot;black&quot;, &quot;red&quot;), lty = c(1, 1)) Se concluye que rezagar la serie de tiempo de vehículos ayuda a identificar patrones y relaciones que pueden ser útiles en el análisis y pronóstico de la variable. 3.4 Estacionalidad Una forma útil de saber si la venta de vehículos tiene estacionalidad, es calcular la función acf que devuelve un gráfico que muestra los coeficientes de correlación para cada rezago. Si la serie de tiempo tiene estacionalidad, se esperaría ver picos en los coeficientes de correlación en los múltiplos de la frecuencia de la serie (por ejemplo, si la frecuencia es mensual, se esperaría ver picos en los coeficientes de correlación para los rezagos 12, 24, 36, etc.). Estos picos indicarían la presencia de patrones de repetición en la serie, lo que sugiere la presencia de estacionalidad. En este sentido, con la gráfica de ACF de la venta de vehículos que se muestra a continuación se afirma que existe un componente estacional en la venta de vehículos, es decir, por ejemplo que la venta de vehículos en Colombia incrementa en el mes de diciembre de cada año y disminuye en enero. Este comportamiento tiene una relación estrecha con la evolución del consumo, en donde, la temporada decembrina refleja un mayor gasto por parte de los hogares colombianos. acf(veh, lag.max = 48) "],["extracción-de-señales.html", "Chapter 4 Extracción de señales 4.1 Descomposición de las series", " Chapter 4 Extracción de señales La extracción de señales en series de tiempo es el proceso de identificar patrones, tendencias y características importantes en los datos de la serie temporal. Es una técnica común utilizada en análisis de series de tiempo para modelar el comportamiento de la serie, predecir valores futuros y entender las relaciones entre las variables. La extracción de señales incluye el análisis de tendencias, el análisis de ciclos, el análisis de estacionalidad, la identificación de puntos atípicos y la descomposición de series de tiempo. El objetivo de la extracción de señales es resumir la información en la serie de tiempo de una manera significativa y comprensible, lo que permite a los analistas y tomadores de decisiones identificar patrones y tendencias a largo plazo, así como patrones a corto plazo en los datos. La extracción de señales también puede ser útil para identificar la relación entre las variables de una serie de tiempo y cómo están cambiando a lo largo del tiempo. En resumen, la extracción de señales en series de tiempo es un proceso crítico para comprender el comportamiento de los datos a lo largo del tiempo y proporciona información valiosa para la toma de decisiones y la predicción de eventos futuros. 4.1 Descomposición de las series Es importante descomponer las series de tiempo porque permite identificar los diferentes componentes que la conforman, es decir, la tendencia, la estacionalidad y la variabilidad aleatoria. Cada uno de estos componentes puede proporcionar información valiosa sobre el comportamiento de la serie a lo largo del tiempo y su relación con otros factores. La tendencia indica que la venta de vehículos refleja un punto de quiebre en marzo 2020 generado por el impacto de la pandemia, luego se evidencia una tendencia positiva de recuperación hasta 2022 y en los primeros dos meses de 2023 se puede observar un ligero cambio de tendencia hacia la desaceleración. La estacionalidad, por otro lado, refleja patrones repetitivos en la serie a lo largo del tiempo. Se identifica un patron estacional en diciembre (incremento de la venta de vehículos por influencia estacional) y enero de cada año (detrimento estacional). Por último, el componente irregular, también conocido como ruido, es la parte de la serie que no se puede explicar por la tendencia y la estacionalidad, y puede ser causada por factores impredecibles y/o eventos aleatorios. En este caso,el covid19, un evento sin precedentes e inesperado. # Utilizamos la función decompose (del paquete cargado previamente &quot;STATS&quot;) library(stats) veh_decomp &lt;- decompose(veh) # Graficar los componentes par(mfrow = c(2, 2)) #Se utiliza para dividir la ventana gráfica en una matriz de 2 filas y 2 columnas plot(veh_decomp$x, main = &quot;Venta de vehículos-Original&quot;, col = &quot;black&quot;, ylab = &quot;Serie de tiempo&quot;) plot(veh_decomp$trend, main = &quot;Tendencia&quot;, col = &quot;blue&quot;, ylab = &quot;Valores&quot;) plot(veh_decomp$seasonal, main = &quot;Estacionalidad&quot;, col = &quot;red&quot;, ylab = &quot;Valores&quot;) plot(veh_decomp$random, main = &quot;Irregularidad&quot;, col = &quot;green&quot;, ylab = &quot;Valores&quot;) "],["modelo-holt-winters.html", "Chapter 5 Modelo Holt-Winters 5.1 Predicciones 5.2 Ajuste de la estacionalidad 5.3 Uso de Forecast: 5.4 Evaluación del modelo 5.5 MAE y RMSE", " Chapter 5 Modelo Holt-Winters Aquí podemos realizar dos ajustes y graficarlos en comparación con los datos originales para ver la calidad de los ajustes variando los paremetros alpha, beta y gamma. HW1 &lt;- HoltWinters(veh) # Custom HoltWinters fitting HW2 &lt;- HoltWinters(veh, alpha=0.2, beta=0.1, gamma=0.1) #Visually evaluate the fits plot(veh, ylab=&quot;Ventas de Vehiculos&quot;, xlim=c(2014,2023)) lines(HW1$fitted[,1], lty=2, col=&quot;blue&quot;) lines(HW2$fitted[,1], lty=2, col=&quot;red&quot;) legend(&quot;bottomleft&quot;, legend = c(&quot;Serie original&quot;, &quot;HW1&quot;,&quot;HW2&quot;), col = c(&quot;black&quot;, &quot;blue&quot;, &quot;red&quot;), lty = 1) 5.1 Predicciones Ambos ajustes parecen seguir bastante bien nuestros datos, así que ahora es el momento de ver cómo se desempeñan al predecir las ventas futura de vehiculos Usando la función “predict”, necesitaremos especificar cuántos puntos de datos queremos predecir en el futuro. Aquí, usaremos un valor de 24 para proyectar 2 años hacia el futuro (recuerdemos, esta es una serie temporal mensual). También nos gustaría tener una noción de los “intervalos de error” asociados con la predicción para tener una idea de nuestra confianza en la predicción. Para hacer esto, establecemos “prediction.interval=TRUE” y el nivel del intervalo de confianza (seleccionado aquí como 0.95). Una vez más, mostraremos un gráfico que incluya la cola de nuestros datos existentes y las nuevas predicciones. HW1.pred &lt;- predict(HW1, 24, prediction.interval = TRUE, level=0.95) #gráfica plot(veh, ylab=&quot;Ventas de Vehiculos&quot;, xlim=c(2014,2025)) lines(HW1$fitted[,1], lty=2, col=&quot;blue&quot;) lines(HW1.pred[,1], col=&quot;red&quot;) lines(HW1.pred[,2], lty=2, col=&quot;orange&quot;) lines(HW1.pred[,3], lty=2, col=&quot;orange&quot;) legend(&quot;bottomleft&quot;, legend = c(&quot;Serie original&quot;, &quot;HW1&quot;,&quot;pronostico&quot;,&quot;límites&quot;), col = c(&quot;black&quot;, &quot;blue&quot;, &quot;red&quot;,&quot;orange&quot;), lty = 1) 5.2 Ajuste de la estacionalidad Cuando realizamos ajustes, también tenemos la opción de ajustar el comportamiento de la componente de estacionalidad. Los ajustes estándar de Holt-Winters utilizan una estacionalidad aditiva, lo que significa que asumen que la amplitud de cualquier componente de estacionalidad es relativamente constante a lo largo de la serie. Sin embargo, si utilizamos una estacionalidad multiplicativa, permitimos que las variaciones estacionales (amplitud) crezcan con el nivel general de los datos. Para ver cómo funciona esto en nuestro caso de ventas de vehículos, crearemos un nuevo ajuste, realizaremos predicciones en el futuro y las compararemos con nuestro ajuste aditivo de HW1. HW3 &lt;- HoltWinters(veh, seasonal = &quot;multiplicative&quot;) HW3.pred &lt;- predict(HW3, 24, prediction.interval = TRUE, level=0.95) plot(veh, ylab=&quot;Ventas de Vehiculos&quot;, xlim=c(2014,2025)) lines(HW3$fitted[,1], lty=2, col=&quot;blue&quot;) lines(HW3.pred[,1], col=&quot;red&quot;) lines(HW3.pred[,2], lty=2, col=&quot;orange&quot;) lines(HW3.pred[,3], lty=2, col=&quot;orange&quot;) legend(&quot;bottomleft&quot;, legend = c(&quot;Serie original&quot;, &quot;HW-mult&quot;,&quot;pronostico&quot;,&quot;límites&quot;), col = c(&quot;black&quot;, &quot;blue&quot;, &quot;red&quot;,&quot;orange&quot;), lty = 1) Como podemos ver, la predicción se parece bastante a nuestro resultado de HW1, los intervalos de confianza muestran una tendencia más conservadora. Para este conjunto de datos, parece que el ajuste multiplicativo podría ser una mejor opción. 5.3 Uso de Forecast: Utilizando nuestro ajuste de Holt-Winters HW1 anterior, podemos utilizar “forecast” para hacer nuevas predicciones e incluir intervalos de confianza del 80% y 95%. library(forecast) HW1_for &lt;- forecast(HW1, h=24, level=c(80,95)) #grafica plot(HW1_for, xlim=c(2014, 2026)) lines(HW1_for$fitted, lty=2, col=&quot;purple&quot;) 5.4 Evaluación del modelo Ahora calculamos la calidad de nuestras predicciones al compilar los valores observados menos los valores predichos para cada punto de datos. Estos se agregan a nuestro modelo de predicción como “$residuals”. Para evaluar mejor las funciones de suavizado que utilizamos en nuestro modelo, queremos verificar que no haya correlaciones entre los errores de predicción. En pocas palabras, si los puntos vecinos en nuestros ajustes constantemente se desvían de los valores observados de manera similar, nuestra línea de ajuste principal no es lo suficientemente reactiva a los cambios en los datos. Para capturar esto, utilizamos la función “acf” para evaluar la correlación de los residuos del ajuste entre puntos con diferentes separaciones temporales en la serie de tiempo (lag). Idealmente, para un lag no nulo, las barras de ACF deben estar dentro del rango de barras azules que se muestran a continuación. Es importante utilizar “na.action=na.pass” porque el último valor de “’$residuals” siempre es NA y, de lo contrario, la función mostrará un error. Una prueba de Ljung-Box también puede indicar la presencia de estas correlaciones. Si obtenemos un valor de p &gt; 0.05, hay un 95% de probabilidad de que los residuos sean independientes. Por último, es útil verificar el histograma de los residuos para asegurarnos de que sigan una distribución normal. Si los residuos están muy sesgados, entonces nuestro modelo puede estar constantemente sobrestimando en una dirección. acf(HW1_for$residuals, lag.max=20, na.action=na.pass) Box.test(HW1_for$residuals, lag=20, type=&quot;Ljung-Box&quot;) ## ## Box-Ljung test ## ## data: HW1_for$residuals ## X-squared = 22.863, df = 20, p-value = 0.2955 hist(HW1_for$residuals) 5.5 MAE y RMSE # Calcular las medidas de precisión accuracy_hw &lt;- accuracy(HW1_for) # Obtener el MSE y el MAE mae_hw &lt;- accuracy_hw[1] rmse_hw &lt;- accuracy_hw[2] # Mostrar los resultados cat(&quot;MAE:&quot;, mae_hw, &quot;\\n&quot;) ## MAE: 259.0023 cat(&quot;RMSE:&quot;, rmse_hw, &quot;\\n&quot;) ## RMSE: 3263.144 "],["aplicación-del-modelo-arima.html", "Chapter 6 Aplicación del Modelo Arima 6.1 Validación de Estacionariedad 6.2 Diferenciación 6.3 Estimación del modelo Auto.arima 6.4 Validación de supuestos 6.5 Predicción corto plazo 6.6 Evaluación del Modelo - MAE y RMSE 6.7 Comparación de los modelos ARIMA y Holt-Winters:", " Chapter 6 Aplicación del Modelo Arima 6.1 Validación de Estacionariedad Un modelo ARIMA requiere que la serie sea estacionaria. Se dice que una serie es estacionaria cuando su media, varianza y autocovarianza son invariantes en el tiempo.Esta suposición tiene un sentido intuitivo: dado que ARIMA usa retardos previos de series para modelar su comportamiento. RECORDAR: En el paso anterior se observó graficamente que la serie original de la venta de vehículos tiene una tendencia y ademas no tiene media ni varianza constante.Con lo cual pudieramos afirmar que visualmente la serie pareciera ser NO ESTACIONARIA. Para validarlo, hacemos el Test de Dickey Fuller:. Este test se basa en una regresión lineal que incluye la propia serie de tiempo y sus rezagos.Las hipótesis respectivas son: Contraste de hipótesis: H0: Serie No estacionaria: Hay raiz unitaria H1: Serie Estacionaria: No hay raiz unitaria Tras realizar la prueba aumentada de Dickey-Fuller (ADF), obtenemos un p-valor = 0.01. Como el p-valor &lt; 0.05, se rechaza H0. En conclusión, la venta de vehículos es una variable Estacionaria. # Cargar el paquete tseries library(tseries) # Realizar prueba de raíz unitaria adf.test(veh) ## ## Augmented Dickey-Fuller Test ## ## data: veh ## Dickey-Fuller = -3.973, Lag order = 4, p-value = 0.0131 ## alternative hypothesis: stationary 6.2 Diferenciación Dado que la venta de vehículos es una variable estacionaria, no se requiere diferenciar la serie. 6.3 Estimación del modelo Auto.arima La función auto.arima() es una herramienta muy útil para ajustar modelos ARIMA automáticamente. La idea detrás de esta función es seleccionar automáticamente el mejor modelo ARIMA para una serie de tiempo dada, basándose en criterios estadísticos como el criterio de información de Akaike (AIC) o el criterio de información bayesiano (BIC). La notación ARIMA(p,d,q)(P,D,Q)[m] se refiere a los parámetros del modelo ARIMA, donde: p: orden de la parte autoregresiva (AR) d: orden de diferenciación (I) q: orden de la parte de media móvil (MA) P: orden de la parte estacional autoregresiva (SAR) D: orden de la diferenciación estacional (SI) Q: orden de la parte estacional de media móvil (SMA) m: número de períodos en una temporada En el modelo ARIMA(1,0,0)(0,1,1)[12], el orden AR es 1, el orden MA es 0, el orden de diferenciación es 0, el orden de SAR es 0, el orden de diferenciación estacional es 1, el orden SMA es 1, y el número de períodos en una temporada es 12. La interpretación de cada parámetro es la siguiente: -El parámetro AR(1) indica que se está utilizando la observación más reciente y la observación anterior para predecir la siguiente observación en la serie. -El parámetro MA(0) indica que no se está utilizando ningún término de media móvil para hacer la predicción. El parámetro de diferenciación d=0 indica que no se aplicó ninguna diferenciación a la serie. El parámetro de diferenciación estacional D=1 indica que se aplicó una diferenciación estacional de primer orden para corregir la estacionalidad en la serie. El parámetro SMA(1) indica que se está utilizando la observación de hace 12 períodos y la observación de hace 1 período para predecir la siguiente observación en la serie. En resumen, el modelo ARIMA(1,0,0)(0,1,1)[12] es un modelo que utiliza la observación más reciente y la observación anterior para predecir la siguiente observación en la serie, y también tiene en cuenta la estacionalidad con una diferencia estacional de primer orden y una media móvil estacional de orden 1. #Corremos la función auto.arima: autoarimaveh=auto.arima(veh) autoarimaveh ## Series: veh ## ARIMA(1,0,0)(0,1,1)[12] with drift ## ## Coefficients: ## ar1 sma1 drift ## 0.6613 -0.6929 -56.3415 ## s.e. 0.0755 0.1143 32.4217 ## ## sigma^2 = 9823446: log likelihood = -930.65 ## AIC=1869.29 AICc=1869.72 BIC=1879.63 6.4 Validación de supuestos Analizamos que los residuos sean Ruido Blanco (los residuos se distribuyen normalmente y no hay autocorrelación entre ellos). Con la prueba de Ljung-Box, se evalúa si hay o no autocorrelación en los residuos: Hipótesis H0: No hay autocorrelación de los residuos H1: Existe autocorrelación de los residuos CONCLUSIÓN: Como el P-value (0.56) es mayor a 0.05 no se rechaza H0. En ese caso si se cumple la condición de los residuos, son ruido blanco (no se correlacionan los errores). Box.test(autoarimaveh$residuals, lag = 20, type = &quot;Ljung-Box&quot;) ## ## Box-Ljung test ## ## data: autoarimaveh$residuals ## X-squared = 18.383, df = 20, p-value = 0.5622 6.5 Predicción corto plazo # Generar pronósticos futuros para 4 años (48 meses) pronostico &lt;- forecast(autoarimaveh, h = 48) # Graficar la serie original y el pronóstico plot(veh, main = &quot;Serie de datos original y pronóstico&quot;, xlab = &quot;Fecha&quot;, ylab = &quot;Número de vehículos&quot;, xlim=c(2014,2026), ylim = c(0, max(veh))) lines(pronostico$mean, col = &quot;red&quot;) legend(&quot;bottomleft&quot;, legend = c(&quot;Serie original&quot;, &quot;Pronóstico&quot;), col = c(&quot;black&quot;, &quot;red&quot;), lty = 1) ## Calculo del AIC Y BIC # Calcular el AIC y el BIC aic &lt;- AIC(autoarimaveh) bic &lt;- BIC(autoarimaveh) # Mostrar los resultados cat(&quot;AIC:&quot;, aic, &quot;\\n&quot;) ## AIC: 1869.292 cat(&quot;BIC:&quot;, bic, &quot;\\n&quot;) ## BIC: 1879.632 6.6 Evaluación del Modelo - MAE y RMSE # Calcular las medidas de precisión accuracy_arima &lt;- accuracy(autoarimaveh) # Obtener el MSE y el MAE mae_arima &lt;- accuracy_arima[1] rmse_arima &lt;- accuracy_arima[2] # Mostrar los resultados cat(&quot;MAE:&quot;, mae_arima, &quot;\\n&quot;) ## MAE: -155.7058 cat(&quot;RMSE:&quot;, rmse_arima, &quot;\\n&quot;) ## RMSE: 2912.711 6.7 Comparación de los modelos ARIMA y Holt-Winters: Comparando los resultados de los modelos ARIMA y Holt-Winters en términos de las métricas de precisión, podemos hacer las siguientes conclusiones: MAE (Mean Absolute Error): El modelo ARIMA tiene un MAE de -155.7058, mientras que el modelo Holt-Winters tiene un MAE de 259.0023. En términos del MAE, el modelo ARIMA muestra un menor error absoluto promedio en comparación con el modelo Holt-Winters. Un valor de MAE más bajo indica que el modelo ARIMA tiene una mejor precisión en los pronósticos en comparación con el modelo Holt-Winters. RMSE (Root Mean Squared Error): El modelo ARIMA tiene un RMSE de 2912.711, mientras que el modelo Holt-Winters tiene un RMSE de 3263.144. En términos del RMSE, el modelo ARIMA muestra un valor más bajo, lo que indica un menor error cuadrático promedio en comparación con el modelo Holt-Winters. Un valor de RMSE más bajo también indica que el modelo ARIMA tiene un mejor ajuste y mayor precisión en los pronósticos en comparación con el modelo Holt-Winters. "],["modelo-facebook-prophet.html", "Chapter 7 Modelo Facebook Prophet 7.1 Analisis de predicción de los Modelos 7.2 Evaluación del Modelo - MAE y RMSE 7.3 Comparación de los modelos ARIMA y Prophet:", " Chapter 7 Modelo Facebook Prophet El modelo Facebook Prophet es una herramienta útil para el análisis y pronóstico de series de tiempo debido a su facilidad de uso, flexibilidad en la configuración del modelo, capacidad de manejo de tendencias y estacionalidades, robustez ante datos faltantes y anomalías, y la disponibilidad de herramientas de visualización y diagnóstico. Esto lo convierte en una opción popular para aplicaciones prácticas en una amplia gama de sectores, incluyendo finanzas, comercio electrónico, planificación de la demanda, entre otros. Para nuestro caso de ventas de vehiculos en Colombia inicimos ajuste del modelo para evaluar rendimeinto: Creamos la serie de tiempo veh &lt;- ts(base$VEH[1:110], frequency = 12, start = c(2014, 1)) Ajustamos el modelo ARIMA arima_model &lt;- forecast::auto.arima(veh) Ajustamos el modelo Prophet veh_data &lt;- data.frame(ds = seq(as.Date(&quot;2014-01-01&quot;), by = &quot;month&quot;, length.out = 110), y = base$VEH[1:110]) prophet_model &lt;- prophet(veh_data) Generamos pronósticos horizon &lt;- 12 # Número de períodos para pronosticar # Pronóstico ARIMA arima_forecast &lt;- forecast(arima_model, h = horizon) # Pronóstico Prophet future_data &lt;- make_future_dataframe(prophet_model, periods = horizon, freq = &quot;month&quot;) prophet_forecast &lt;- predict(prophet_model, future_data) # Convertir los pronósticos de Prophet a una serie de tiempo prophet_forecast_ts &lt;- ts(prophet_forecast$yhat, frequency = horizon, start = c(2014, 1)) # Graficar los pronósticos y los datos originales plot(veh, xlab = &quot;Años&quot;, ylab = &quot;No. de vehículos&quot;, main = &quot;Venta de vehículos en Colombia (original)&quot;) lines(arima_forecast$mean, col = &quot;blue&quot;, lty = 1) lines(prophet_forecast_ts, col = &quot;red&quot;, lty = 1) legend(&quot;topleft&quot;, legend = c(&quot;Datos originales&quot;, &quot;ARIMA&quot;, &quot;Prophet&quot;), col = c(&quot;black&quot;, &quot;blue&quot;, &quot;red&quot;), lty = c(1, 1, 1)) 7.1 Analisis de predicción de los Modelos Al comparar los datos que predice cada modelo en el futuro, es evidente que el modelo Prophet presenta una mejor capacidad para capturar las fluctuaciones y patrones en la serie de tiempo de ventas de vehículos en Colombia. Los pronósticos generados por Prophet se ajustan más de cerca a los datos reales y reflejan de manera más precisa las tendencias observadas en la serie. En contraste, los pronósticos del modelo ARIMA muestran ciertas desviaciones y no logran capturar completamente las variaciones en la serie de tiempo. Esto se puede observar al comparar las líneas de pronóstico en los períodos futuros. Mientras que los pronósticos de Prophet siguen de cerca las fluctuaciones y cambios en la serie, los pronósticos de ARIMA pueden estar más alejados de los valores reales y no reflejar con precisión las tendencias observadas. Esto se confirma al evaluar las métricas de desempeño (MAE y RMSE), donde el modelo Prophet muestra valores más bajos en comparación con el modelo ARIMA. Un MAE y RMSE más bajo indica una mayor precisión en los pronósticos, lo que respalda aún más la superioridad de Prophet en términos de predicción de la serie de tiempo. 7.2 Evaluación del Modelo - MAE y RMSE Calculamos MAE y RMSE para ARIMA arima_forecast_values &lt;- as.numeric(arima_forecast$mean) mae_arima &lt;- mean(abs(arima_forecast_values - veh)) rmse_arima &lt;- sqrt(mean((arima_forecast_values - veh)^2)) Calculamos MAE y RMSE para Prophet mae_prophet &lt;- mean(abs(prophet_forecast_ts - veh)) rmse_prophet &lt;- sqrt(mean((prophet_forecast_ts - veh)^2)) Imprimimos resultados cat(&quot;ARIMA - MAE:&quot;, mae_arima, &quot;\\n&quot;) ## ARIMA - MAE: 4910.315 cat(&quot;ARIMA - RMSE:&quot;, rmse_arima, &quot;\\n&quot;) ## ARIMA - RMSE: 6504.895 cat(&quot;Prophet - MAE:&quot;, mae_prophet, &quot;\\n&quot;) ## Prophet - MAE: 2330.432 cat(&quot;Prophet - RMSE:&quot;, rmse_prophet, &quot;\\n&quot;) ## Prophet - RMSE: 3220.954 7.3 Comparación de los modelos ARIMA y Prophet: Comparando los valores de MAE y RMSE, podemos observar que el modelo Prophet tiene un mejor desempeño en términos de precisión en los pronósticos en comparación con el modelo ARIMA. Esto se evidencia en los valores más bajos tanto en el MAE como en el RMSE para el modelo Prophet. El MAE para el modelo Prophet es de 2330.432, lo que indica una menor diferencia absoluta promedio entre los valores pronosticados y los valores reales. Por otro lado, el MAE para el modelo ARIMA es de 4910.315, lo que implica una mayor diferencia promedio entre los pronósticos y los valores reales. En cuanto al RMSE, el modelo Prophet también muestra un mejor desempeño con un valor de 3220.954, en comparación con el modelo ARIMA que tiene un RMSE de 6504.895. Esto indica que el modelo Prophet tiene una menor magnitud de error cuadrático medio en comparación con el modelo ARIMA. Estos resultados sugieren que el modelo Prophet es más preciso en la predicción de la serie de tiempo de ventas de vehículos en Colombia, en comparación con el modelo ARIMA utilizado en este análisis. En conclusión, en base a los resultados obtenidos, el modelo Prophet muestra un mejor desempeño en términos de precisión en los pronósticos para la serie de tiempo de ventas de vehículos en Colombia, con valores más bajos tanto en el MAE como en el RMSE. "],["redes-neuronales-recurrentes-modelos-elman-y-jordan.html", "Chapter 8 Redes Neuronales Recurrentes (Modelos Elman y Jordan) 8.1 Estimación del error comparativo de los modelos con los valores actuales observados. 8.2 Conclusiones de modelos de redes neuronales ELMAN y JORDAN.", " Chapter 8 Redes Neuronales Recurrentes (Modelos Elman y Jordan) Una red neuronal recurrente no tiene una estructura de capas definida, sino que permiten conexiones arbitrarias entre las neuronas, incluso pudiendo crear ciclos, con esto se consigue crear la temporalidad, permitiendo que la red tenga memoria. Los RNN se denominan recurrentes porque realizan la misma tarea para cada elemento de una secuencia, y la salida depende de los cálculos anteriores. MODELO ELMAN En las redes de Elman, las entradas de estas neuronas, se toman desde las salidas de las neuronas de una de las capas ocultas, y sus salidas se conectan de nuevo en las entradas de esta misma capa, lo que proporciona una especie de memoria sobre el estado anterior de dicha capa. Creamos la serie de tiempo veh &lt;- read_excel(&quot;C:/Users/portatil/DatosR/veh.xlsx&quot;) Y=ts(veh, start = c(2014,1),frequency = 12) Damos formato de serie de tiempo Y1=ts(veh, start = c(2014,1), end=c(2022,02),frequency = 12) length(Y1) ## [1] 98 Para aplicar redes neuronales debemos normalizar datos Para ello hemos asociado a nuestro dataset de base una variable “Z” y a partir de esta hemos realizar la normalización a través de la variable “S”. Z &lt;- as.ts(Y1,F) S &lt;- (Z-min(Z))/(max(Z)-min(Z)) plot(S) A continuación comprobamos el numero de filas totales que contiene nuestro dataset. tamano_total &lt;- length(S) tamano_total ## [1] 98 Ahora dividiremos los conjuntos de entrenamiento en un 75% y prueba en un 25% respectivamente. tamano_train &lt;- round(tamano_total*0.75, digits = 0) train &lt;- 0:(tamano_train-1) train ## [1] 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ## [26] 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 ## [51] 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 test &lt;- (tamano_train):tamano_total test ## [1] 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 Ahora crearemos un dataframe con n columnas, cada una de las cuales adelantara un valor de la serie en el futuro, a través de una variable tipo zoo, equivalente al #periodo de retardo de la serie. y &lt;- as.zoo(S) x1 &lt;- Lag(y, k = 1) x2 &lt;- Lag(y, k = 2) x3 &lt;- Lag(y, k = 3) x4 &lt;- Lag(y, k = 4) x5 &lt;- Lag(y, k = 5) x6 &lt;- Lag(y, k = 6) x7 &lt;- Lag(y, k = 7) x8 &lt;- Lag(y, k = 8) x9 &lt;- Lag(y, k = 9) x10 &lt;- Lag(y, k = 10) x11 &lt;- Lag(y, k = 11) x12 &lt;- Lag(y, k = 12) slogN &lt;- cbind(y,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12) DT::datatable(slogN) A continuación eliminaremos los valores NA producidos al desplazar la serie: slogN1 &lt;- slogN[-(1:12),] DT::datatable(slogN1) Luego definimos los valores de entrada y salida de la red neuronal: inputs &lt;- slogN1[,2:13] outputs &lt;- slogN1[,1] Ahora crearemos la red de Elman, probando diferentes tipos de combinaciones de neuronas en las capas ocultas e iteraciones máximas, ademas del ritmo de aprendizaje, para ajustar lo mejor posible la curva de predicción a la del modelo de la serie. De esta forma hemos llegado a estos valores a la hora de crear nuestra red. Asi mismo ponemos una semilla para que el resultado sea reproducible. library(RSNNS) set.seed(42) fit&lt;-elman(inputs[train],outputs[train],size=5,learnFuncParams=c(0.1), maxit=10000) #En la gráfica siguiente vemos como evoluciona el error de la red con el numero de iteraciones para los parámetros expuestos. plotIterativeError(fit, main = &quot;Iterative Error for 5 Neuron&quot;) En la gráfica anterior se observa una convergencia rápida hacia cero, se espera entonces un ajuste rápido del modelo. Ahora realizamos la predicción con el resto de los términos de la serie que son los datos #seleccionados para test, pasamos pues una vez entrenada a probarla y a representarla #graficamente para ver el ajuste del modelo. y &lt;- as.vector(outputs[-test]) plot(y,type=&quot;l&quot;) pred &lt;- predict(fit, inputs[-test]) lines(pred,col = &quot;red&quot;) legend(&quot;topleft&quot;, legend = c(&quot;Datos Reales&quot;, &quot;Datos Predichos&quot;), col = c(&quot;black&quot;, &quot;red&quot;), lty = c(1, 1)) El ajuste predice bastante bien con los parametros elegidos, pues la curva del modelo de la serie y la de la prediccion parecen bastante ajustadas. Esta representacion grafica se puede utilizar para ir ajustando la prediccion y el modelo a medida que vamos probando diferentes parametros de la red de Elman, de forma que la curva del modelo y de la prediccion queden lo mas ajustados posibles. Ahora gracias al efecto memoria vamos a adelantarle a la serie al menos en un valor con una precision muy buena. Para ello volveremos a introducir los datos de entrenamiento. predictions &lt;- predict(fit,inputs[-train]) predictions ## [,1] ## feb. 2021 0.3329012 ## mar. 2021 0.2609815 ## abr. 2021 0.0670051 ## may. 2021 0.4164404 ## jun. 2021 0.3693653 ## jul. 2021 0.4730132 ## ago. 2021 0.4960409 ## sept. 2021 0.5433677 ## oct. 2021 0.5297236 ## nov. 2021 0.6084241 ## dic. 2021 0.6646473 ## ene. 2022 0.3588158 ## feb. 2022 0.5120363 Posteriori desnormalizaremos los datos: mod1 &lt;- predictions*(max(Z)-min(Z))+min(Z) mod1 ## [,1] ## feb. 2021 13591.640 ## mar. 2021 10702.193 ## abr. 2021 2908.997 ## may. 2021 16947.908 ## jun. 2021 15056.622 ## jul. 2021 19220.779 ## ago. 2021 20145.938 ## sept. 2021 22047.342 ## oct. 2021 21499.177 ## nov. 2021 24661.048 ## dic. 2021 26919.869 ## ene. 2022 14632.786 ## feb. 2022 20788.571 Aquí vemos la gráfica con los valores pronosticados con la linea roja. -Los valores que adelantamos en el tiempo corresponden a mod1, de los cuales adelantaremos 12 meses a futuro para nuestro estudio. Ahora veamos la representación de los valores predecidos para el siguiente periodo. x &lt;- 1:(tamano_total+length(mod1)) y &lt;- c(as.vector(Z),mod1) plot(x[1:tamano_total], y[1:tamano_total],col = &quot;blue&quot;, type=&quot;l&quot;) lines( x[(tamano_total):length(x)], y[(tamano_total):length(x)], col=&quot;red&quot;) length(y) ## [1] 111 MODELO JORDAN En las redes Jordan, la diferencia esta en que la entrada de las neuronas de la capa de contexto se toma desde la salida de la red. Realizamos las mismas operaciones que con la red Elman, sustituyendo el modelo, obtenemos el resultado para la red Jordan. set.seed(42) fit &lt;-jordan(inputs[train],outputs[train],size=5,learnFuncParams=c(0.1), maxit=35000) plotIterativeError(fit, main = &quot;Iterative Error for 5 Neuron&quot;) y &lt;- as.vector(outputs[-test]) plot(y, type = &quot;l&quot;, main = &quot;Comparación de Datos Reales y Predichos&quot;, xlab = &quot;Índice&quot;, ylab = &quot;Valores&quot;) pred &lt;- predict(fit, inputs[-test]) lines(pred, col = &quot;red&quot;) legend(&quot;topleft&quot;, legend = c(&quot;Datos Reales&quot;, &quot;Datos Predichos&quot;), col = c(&quot;black&quot;, &quot;red&quot;), lty = c(1, 1)) predictions &lt;- predict(fit,inputs[-train]) mod2 &lt;- predictions*(max(Z)-min(Z))+min(Z) mod2 ## [,1] ## feb. 2021 3884.444 ## mar. 2021 33576.846 ## abr. 2021 11833.495 ## may. 2021 14823.377 ## jun. 2021 13574.293 ## jul. 2021 20448.654 ## ago. 2021 18429.020 ## sept. 2021 19670.796 ## oct. 2021 20747.208 ## nov. 2021 27825.488 ## dic. 2021 25797.013 ## ene. 2022 13655.142 ## feb. 2022 17335.238 x &lt;- 1:(tamano_total+length(mod2)) y &lt;- c(as.vector(Z),mod2) plot(x[1:tamano_total], y[1:tamano_total],col = &quot;blue&quot;, type=&quot;l&quot;) lines( x[(tamano_total):length(x)], y[(tamano_total):length(x)], col=&quot;red&quot;) 8.1 Estimación del error comparativo de los modelos con los valores actuales observados. data=veh[99:110,] data_real &lt;- ts(data, start = c(2022,3), end=c(2023,02), frequency = 12) data_real ## Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec ## 2022 20837 20622 22411 23306 23233 24386 23871 22577 22625 21880 ## 2023 13852 15761 Para Elman y Jordan al no ser modelos con forecast, lo convertimos en series de tiempo #para que lo acepte el comando accuracy.De tal forma que: mod1[1:12] ## [1] 13591.640 10702.193 2908.997 16947.908 15056.622 19220.779 20145.938 ## [8] 22047.342 21499.177 24661.048 26919.869 14632.786 m1 &lt;- mod1[1:12] mod1c &lt;- ts(m1, frequency=12,start=c(2022,3)) mod1c ## Jan Feb Mar Apr May Jun Jul ## 2022 13591.640 10702.193 2908.997 16947.908 15056.622 ## 2023 26919.869 14632.786 ## Aug Sep Oct Nov Dec ## 2022 19220.779 20145.938 22047.342 21499.177 24661.048 ## 2023 m2 &lt;- mod2[1:12] mod2c &lt;- ts(m2, frequency=12,start=c(2022,3)) mod2c ## Jan Feb Mar Apr May Jun Jul ## 2022 3884.444 33576.846 11833.495 14823.377 13574.293 ## 2023 25797.013 13655.142 ## Aug Sep Oct Nov Dec ## 2022 20448.654 18429.020 19670.796 20747.208 27825.488 ## 2023 ELMAN (RRN) accuracy(mod1c,data_real) ## ME RMSE MAE MPE MAPE ACF1 Theil&#39;s U ## Test set 3918.892 8467.508 6560.378 14.71541 32.55703 0.5280143 3.23668 JORDAN accuracy(mod2c,data_real) ## ME RMSE MAE MPE MAPE ACF1 Theil&#39;s U ## Test set 2591.269 8999.551 7732.16 8.647962 38.0191 -0.1205701 2.92748 8.2 Conclusiones de modelos de redes neuronales ELMAN y JORDAN. Para el modelo ELMAN (RRN): El error medio (ME) es de 3918.892, indicando una ligera tendencia a subestimar los valores reales en promedio. El error cuadrático medio (RMSE) es de 8467.508, lo que sugiere una variabilidad considerable entre los valores predichos y los valores reales. El error absoluto medio (MAE) es de 6560.378, que representa la diferencia promedio entre los valores predichos y los valores reales. El error porcentual medio (MPE) es de 14.71541, lo que indica una tendencia a subestimar los valores reales en promedio. El error absoluto porcentual medio (MAPE) es de 32.55703, que representa la diferencia promedio entre los valores predichos y los valores reales en términos porcentuales. El coeficiente de autocorrelación (ACF1) es de 0.5280143, lo que sugiere cierta correlación entre los valores predichos y los valores reales. El índice de Theil (Theil’s U) es de 3.23668, proporcionando una medida de la relación entre el error de predicción y la variabilidad de los datos reales. Para el modelo JORDAN: El error medio (ME) es de 2591.269, indicando una ligera tendencia a subestimar los valores reales en promedio. El error cuadrático medio (RMSE) es de 8999.551, lo que sugiere una mayor variabilidad entre los valores predichos y los valores reales en comparación con el modelo ELMAN. El error absoluto medio (MAE) es de 7732.16, que representa la diferencia promedio entre los valores predichos y los valores reales. El error porcentual medio (MPE) es de 8.647962, lo que indica una tendencia a subestimar los valores reales en promedio. El error absoluto porcentual medio (MAPE) es de 38.0191, que representa una mayor diferencia promedio entre los valores predichos y los valores reales en términos porcentuales en comparación con el modelo ELMAN. El coeficiente de autocorrelación (ACF1) es de -0.1205701, lo que sugiere una correlación débil o falta de correlación entre los valores predichos y los valores reales. El índice de Theil (Theil’s U) es de 2.92748, proporcionando una medida de la relación entre el error de predicción y la variabilidad de los datos reales. En conclusión, según los resultados presentados, el modelo ELMAN (RRN) muestra un error ligeramente menor en términos de RMSE y MAE en comparación con el modelo JORDAN. También exhibe una correlación más fuerte entre los valores predichos y los valores reales, como se indica por el coeficiente de autocorrelación (ACF1). "]]
